{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import glob\n",
    "import docx2txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "## First step read the different csv files that we extract from Indeed\n",
    "def path(x):\n",
    "    all_files = glob.glob(x + \"/*.csv\")\n",
    "    return all_files\n",
    "\n",
    "## Insert the path of the folder that contains different csv files.\n",
    "all_files = path(r\"C:\\Users\\nikos\\Desktop\\dataframes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(182, 7)"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def create_df(files, li):\n",
    "    for filename in files:\n",
    "        df = pd.read_csv(filename, index_col=None, header=0)\n",
    "        li.append(df)\n",
    "        df = pd.concat(li, axis=0, ignore_index=True)\n",
    "    return df\n",
    "df = create_df(all_files, [])\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Droped Duplicates\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(171, 7)"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Remove duplicates\n",
    "def Shape(df):\n",
    "    shape = [df.shape]\n",
    "    if ([x[0] for x in shape][0]) > len(df[\"Job Url\"].unique()):\n",
    "        print(\"Droped Duplicates\")\n",
    "        df = df.drop_duplicates(subset=['Job Url'])\n",
    "        return df\n",
    "    else:\n",
    "        print(\"We don't have Duplicates\")\n",
    "        return df\n",
    "\n",
    "new_df = Shape(df)\n",
    "new_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "## reading the canditate's cv\n",
    "def read_cv(name):\n",
    "    # read the word file\n",
    "    x =  docx2txt.process(name)\n",
    "    return x\n",
    "    \n",
    "cv = read_cv(\"monster-cv-template-admin-assistant.docx\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Extract candidate email, and applying some basic text preprocessingÂ \n",
    "def text_pre(x):\n",
    "    ## Applying some text preprocessing\n",
    "    text = x.replace(\"\\n\", \"\")\n",
    "    return text\n",
    "def extract_email(x):\n",
    "    ## Extracting the email address using regex  \n",
    "    import re\n",
    "    match = re.search(r'[\\w\\.-]+@[\\w\\.-]+', x)\n",
    "    email = match.group(0)\n",
    "    return email\n",
    "    \n",
    "text = text_pre(cv)\n",
    "email = extract_email(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Job Title</th>\n",
       "      <th>Job Url</th>\n",
       "      <th>Company</th>\n",
       "      <th>Location</th>\n",
       "      <th>Summary</th>\n",
       "      <th>Posting Date</th>\n",
       "      <th>Desc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>167</th>\n",
       "      <td>Order Picker Warehouse Operative</td>\n",
       "      <td>http://www.indeed.com/rc/clk?jk=8b7dd86955a721...</td>\n",
       "      <td>Premier Work Support</td>\n",
       "      <td>London</td>\n",
       "      <td>To be successful in this role you need warehou...</td>\n",
       "      <td>23 days ago</td>\n",
       "      <td>We have an exciting opportunity to join a very...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168</th>\n",
       "      <td>Warehouse Operative - Immediate Start</td>\n",
       "      <td>http://www.indeed.com/pagead/clk?mo=r&amp;ad=-6NYl...</td>\n",
       "      <td>ABC Depot</td>\n",
       "      <td>Finchley Central Station</td>\n",
       "      <td>Must have 3-5 years Builders Merchant experien...</td>\n",
       "      <td>30+ days ago</td>\n",
       "      <td>DutiesMust have 3-5 years Builders Merchant ex...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>169</th>\n",
       "      <td>Warehouse Operative</td>\n",
       "      <td>http://www.indeed.com/company/White-Van-Gentle...</td>\n",
       "      <td>White Van Gentlemen</td>\n",
       "      <td>Earlsfield</td>\n",
       "      <td>Organizing / keeping tidy the warehouse.\\nPall...</td>\n",
       "      <td>30+ days ago</td>\n",
       "      <td>Job DescriptionWhite Van Gentlemen is a white ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>170</th>\n",
       "      <td>Warehouse Operative - Picker / Packer / Replen</td>\n",
       "      <td>http://www.indeed.com/company/All-Pet-Solution...</td>\n",
       "      <td>All Pet Solutions</td>\n",
       "      <td>Uxbridge</td>\n",
       "      <td>Working within a team of warehouse operatives....</td>\n",
       "      <td>3 days ago</td>\n",
       "      <td>All Pet Solutions is an online market leader a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>171</th>\n",
       "      <td>NaN</td>\n",
       "      <td>name@hotmail.com</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Uschi BarkerAddress: Flat 0, Any Road, Any Tow...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          Job Title  \\\n",
       "167                Order Picker Warehouse Operative   \n",
       "168           Warehouse Operative - Immediate Start   \n",
       "169                             Warehouse Operative   \n",
       "170  Warehouse Operative - Picker / Packer / Replen   \n",
       "171                                             NaN   \n",
       "\n",
       "                                               Job Url               Company  \\\n",
       "167  http://www.indeed.com/rc/clk?jk=8b7dd86955a721...  Premier Work Support   \n",
       "168  http://www.indeed.com/pagead/clk?mo=r&ad=-6NYl...             ABC Depot   \n",
       "169  http://www.indeed.com/company/White-Van-Gentle...   White Van Gentlemen   \n",
       "170  http://www.indeed.com/company/All-Pet-Solution...     All Pet Solutions   \n",
       "171                                   name@hotmail.com                   NaN   \n",
       "\n",
       "                     Location  \\\n",
       "167                    London   \n",
       "168  Finchley Central Station   \n",
       "169                Earlsfield   \n",
       "170                  Uxbridge   \n",
       "171                       NaN   \n",
       "\n",
       "                                               Summary  Posting Date  \\\n",
       "167  To be successful in this role you need warehou...   23 days ago   \n",
       "168  Must have 3-5 years Builders Merchant experien...  30+ days ago   \n",
       "169  Organizing / keeping tidy the warehouse.\\nPall...  30+ days ago   \n",
       "170  Working within a team of warehouse operatives....    3 days ago   \n",
       "171                                                NaN           NaN   \n",
       "\n",
       "                                                  Desc  \n",
       "167  We have an exciting opportunity to join a very...  \n",
       "168  DutiesMust have 3-5 years Builders Merchant ex...  \n",
       "169  Job DescriptionWhite Van Gentlemen is a white ...  \n",
       "170  All Pet Solutions is an online market leader a...  \n",
       "171  Uschi BarkerAddress: Flat 0, Any Road, Any Tow...  "
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## So, now we can add these two attributes as a row to our main dataframe\n",
    "def insert_row(email, text, df):\n",
    "    new_row = {'Job Url':email, 'Desc': text}\n",
    "    df= df.append(new_row, ignore_index=True)\n",
    "    return df\n",
    "\n",
    "new_df = insert_row(email, text, new_df)\n",
    "new_df.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Perfect the new candidate is into our main dataframe, So now we can start developing the recommendation  model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\nikos\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     C:\\Users\\nikos\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\nikos\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\nikos\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "## Applying text preprocessing modules to Desc column\n",
    "## text preprocessing \n",
    "import nltk \n",
    "\n",
    "nltk.download('punkt') \n",
    "\n",
    "nltk.download('averaged_perceptron_tagger') \n",
    "\n",
    "nltk.download('wordnet') \n",
    "\n",
    "    \n",
    "from nltk.stem import WordNetLemmatizer \n",
    "\n",
    "lemmatizer = WordNetLemmatizer() \n",
    "\n",
    "  \n",
    "\n",
    "from nltk.corpus import stopwords \n",
    "\n",
    "nltk.download('stopwords') \n",
    "\n",
    "stop_words = set(stopwords.words('english')) \n",
    "\n",
    "  \n",
    "\n",
    "VERB_CODES = {'VB', 'VBD', 'VBG', 'VBN', 'VBP', 'VBZ'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_sentences(text): \n",
    "\n",
    "    text = text.lower() \n",
    "    temp_sent =[] \n",
    "    words = nltk.word_tokenize(text) \n",
    "    tags = nltk.pos_tag(words) \n",
    "    \n",
    "    for i, word in enumerate(words): \n",
    "        if tags[i][1] in VERB_CODES:   \n",
    "            lemmatized = lemmatizer.lemmatize(word, 'v') \n",
    "        else: \n",
    "            lemmatized = lemmatizer.lemmatize(word) \n",
    "        if lemmatized not in stop_words and lemmatized.isalpha(): \n",
    "            temp_sent.append(lemmatized) \n",
    "\n",
    "    finalsent = ' '.join(temp_sent) \n",
    "    finalsent = finalsent.replace(\"n't\", \" not\") \n",
    "    finalsent = finalsent.replace(\"'m\", \" am\") \n",
    "    finalsent = finalsent.replace(\"'s\", \" is\") \n",
    "    finalsent = finalsent.replace(\"'re\", \" are\") \n",
    "    finalsent = finalsent.replace(\"'ll\", \" will\") \n",
    "    finalsent = finalsent.replace(\"'ve\", \" have\") \n",
    "    finalsent = finalsent.replace(\"'d\", \" would\") \n",
    "\n",
    "    return finalsent \n",
    "\n",
    "\n",
    "## Creating a new column that we applied the text manipulation function \n",
    "new_df[\"Desc proc\"] = new_df[\"Desc\"].apply(preprocess_sentences) \n",
    "final_data = new_df[[\"Job Url\", \"Desc proc\"]]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### After data preprocessing, we are ready to develop the recomandation model. I will use the Cosine similarity metric in order to determine text similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.         0.04126661 0.18151655 ... 0.08260162 0.07620499 0.10476454]\n",
      " [0.04126661 1.         0.10875201 ... 0.14913013 0.0880522  0.09126919]\n",
      " [0.18151655 0.10875201 1.         ... 0.18950196 0.14201333 0.15494925]\n",
      " ...\n",
      " [0.08260162 0.14913013 0.18950196 ... 1.         0.26988337 0.12259438]\n",
      " [0.07620499 0.0880522  0.14201333 ... 0.26988337 1.         0.07983581]\n",
      " [0.10476454 0.09126919 0.15494925 ... 0.12259438 0.07983581 1.        ]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity \n",
    "\n",
    "count = CountVectorizer()\n",
    "count_matrix = count.fit_transform(final_data['Desc proc'])\n",
    "cosine_sim = cosine_similarity(count_matrix)\n",
    "print(cosine_sim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Finding the index of the candidate's cv.\n",
    "def get_index_from_url(url):\n",
    "    return final_data[final_data[\"Job Url\"] == url].index.values[0]\n",
    "    \n",
    "url = get_index_from_url(email)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(171, 0.9999999999999986),\n",
       " (109, 0.26764693139028045),\n",
       " (13, 0.2418728449756597),\n",
       " (17, 0.23551119173538854),\n",
       " (14, 0.2288626653694555),\n",
       " (149, 0.22623995411025635),\n",
       " (15, 0.22403305120122177),\n",
       " (21, 0.22403305120122177),\n",
       " (146, 0.22399601788396722),\n",
       " (23, 0.22154790046665213),\n",
       " (24, 0.21782118162804753),\n",
       " (27, 0.21782118162804753),\n",
       " (28, 0.21782118162804753),\n",
       " (29, 0.21782118162804753),\n",
       " (30, 0.21782118162804753),\n",
       " (32, 0.21782118162804753),\n",
       " (33, 0.21782118162804753),\n",
       " (36, 0.21782118162804753),\n",
       " (38, 0.21782118162804753),\n",
       " (39, 0.21782118162804753),\n",
       " (41, 0.21782118162804753),\n",
       " (42, 0.21782118162804753),\n",
       " (43, 0.21782118162804753),\n",
       " (44, 0.21782118162804753),\n",
       " (45, 0.21782118162804753),\n",
       " (52, 0.21782118162804753),\n",
       " (132, 0.21746852605578149),\n",
       " (118, 0.21670406454457042),\n",
       " (37, 0.21532761076060403),\n",
       " (25, 0.21181345437818172),\n",
       " (84, 0.21115368309936872),\n",
       " (135, 0.20586606098082774),\n",
       " (164, 0.204609985676822),\n",
       " (35, 0.2013488589318756),\n",
       " (11, 0.19818626434583295),\n",
       " (154, 0.19618288604953701),\n",
       " (50, 0.19493285163319293),\n",
       " (142, 0.19410175047343156),\n",
       " (123, 0.19171181471114337),\n",
       " (98, 0.18837809238252295),\n",
       " (138, 0.18759202734336106),\n",
       " (102, 0.1842496838174533),\n",
       " (16, 0.1827676932405473),\n",
       " (161, 0.18245059479484071),\n",
       " (12, 0.1803141697242315),\n",
       " (79, 0.17993510463857143),\n",
       " (167, 0.17721552591365922),\n",
       " (80, 0.17710743919645838),\n",
       " (75, 0.17548816740416412),\n",
       " (19, 0.17467497698445048),\n",
       " (92, 0.17320469537841088),\n",
       " (117, 0.17242301931446427),\n",
       " (130, 0.17242301931446427),\n",
       " (4, 0.17238473259593615),\n",
       " (95, 0.17153177948814874),\n",
       " (114, 0.17125798557141952),\n",
       " (105, 0.1709984465061396),\n",
       " (9, 0.1703727074605764),\n",
       " (163, 0.16901415901350975),\n",
       " (110, 0.16895124332533829),\n",
       " (34, 0.16823082982871956),\n",
       " (91, 0.16482659289738186),\n",
       " (147, 0.16177490180508747),\n",
       " (49, 0.16152176757950548),\n",
       " (133, 0.1613396085010066),\n",
       " (100, 0.1605414681373464),\n",
       " (51, 0.16026002568782408),\n",
       " (5, 0.15977729015977948),\n",
       " (7, 0.15926144393053876),\n",
       " (99, 0.15873989540497527),\n",
       " (87, 0.15670345065236063),\n",
       " (124, 0.15608377411859448),\n",
       " (2, 0.15494925090586797),\n",
       " (115, 0.1547573794962791),\n",
       " (104, 0.154467868458913),\n",
       " (85, 0.15261360626580825),\n",
       " (46, 0.1520438949410718),\n",
       " (148, 0.15129341391153972),\n",
       " (82, 0.15045395067205547),\n",
       " (31, 0.1504277527223641),\n",
       " (158, 0.1494542455766022),\n",
       " (140, 0.1491466604311907),\n",
       " (126, 0.14913196835013934),\n",
       " (139, 0.14913196835013934),\n",
       " (78, 0.14848978425425288),\n",
       " (131, 0.14773457484849806),\n",
       " (134, 0.14601136020664918),\n",
       " (3, 0.1431971603389681),\n",
       " (159, 0.1421230444142423),\n",
       " (150, 0.14197843893903545),\n",
       " (74, 0.1413925557978934),\n",
       " (111, 0.14049489344341398),\n",
       " (58, 0.14001460384724315),\n",
       " (121, 0.1396596609567313),\n",
       " (70, 0.13902560127357833),\n",
       " (64, 0.1378229549465344),\n",
       " (69, 0.1378229549465344),\n",
       " (160, 0.1373972776636087),\n",
       " (103, 0.13601332514646683),\n",
       " (88, 0.13589579875915886),\n",
       " (66, 0.13588850174216027),\n",
       " (48, 0.13509093288467733),\n",
       " (61, 0.1350645338473573),\n",
       " (63, 0.13502558977412307),\n",
       " (151, 0.13415484911385347),\n",
       " (108, 0.13150028850277393),\n",
       " (113, 0.12893279948067557),\n",
       " (68, 0.12795672621912593),\n",
       " (90, 0.12776880210071495),\n",
       " (26, 0.12751534261266764),\n",
       " (71, 0.1252175806694523),\n",
       " (107, 0.1248028754913774),\n",
       " (55, 0.12407401716646861),\n",
       " (94, 0.12379477468310071),\n",
       " (10, 0.12319152471463941),\n",
       " (169, 0.12259438283709695),\n",
       " (129, 0.12253730201259222),\n",
       " (93, 0.12202888051842836),\n",
       " (40, 0.12187784332052673),\n",
       " (157, 0.12000511275276997),\n",
       " (137, 0.11898953286750938),\n",
       " (47, 0.11879182740340229),\n",
       " (8, 0.11812651790609877),\n",
       " (56, 0.1177562508083216),\n",
       " (53, 0.11749351708320904),\n",
       " (119, 0.11707888512507547),\n",
       " (125, 0.11558828537169787),\n",
       " (76, 0.1149544624193164),\n",
       " (122, 0.11314786746106087),\n",
       " (128, 0.11199800894198361),\n",
       " (116, 0.11156306357482945),\n",
       " (101, 0.11109406502849309),\n",
       " (6, 0.1107739502333261),\n",
       " (120, 0.11049723957430968),\n",
       " (156, 0.10666682797768161),\n",
       " (0, 0.10476454436543672),\n",
       " (54, 0.10393777401525262),\n",
       " (89, 0.10217536404822063),\n",
       " (20, 0.1006421324789799),\n",
       " (86, 0.10048659849357923),\n",
       " (144, 0.0999142378772421),\n",
       " (67, 0.09739145163179626),\n",
       " (59, 0.09481602710335708),\n",
       " (73, 0.0945206605754461),\n",
       " (97, 0.09439929508487852),\n",
       " (106, 0.09417632186960222),\n",
       " (143, 0.0924121278101539),\n",
       " (136, 0.0914459913718425),\n",
       " (1, 0.09126918636192564),\n",
       " (165, 0.08847169940833166),\n",
       " (81, 0.08835982699717797),\n",
       " (112, 0.08561975750816472),\n",
       " (145, 0.08251699166763235),\n",
       " (141, 0.08108137721521287),\n",
       " (22, 0.08032711545197997),\n",
       " (170, 0.07983581350097282),\n",
       " (18, 0.0776566469211916),\n",
       " (62, 0.0765145008720031),\n",
       " (168, 0.07404270764561009),\n",
       " (152, 0.07384930015555075),\n",
       " (96, 0.07170541798161495),\n",
       " (83, 0.06945821656819366),\n",
       " (162, 0.06943735511207867),\n",
       " (65, 0.06641183893896326),\n",
       " (127, 0.06224158018602046),\n",
       " (153, 0.05726570111941077),\n",
       " (60, 0.056756964050649006),\n",
       " (77, 0.050087032267780926),\n",
       " (72, 0.044227929938691186),\n",
       " (155, 0.03712697844207514),\n",
       " (166, 0.03712697844207514),\n",
       " (57, 0.033062367956624455)]"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Creating a list with similarily of our CV with the job description\n",
    "similar_jobs = list(enumerate(cosine_sim[url]))\n",
    "\n",
    "## Sort the list in descending order\n",
    "sorted_similar_jobs = sorted(similar_jobs, key=lambda x:x[1], reverse=True)\n",
    "sorted_similar_jobs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "171    name@hotmail.com\n",
      "Name: Job Url, dtype: object\n",
      "109    http://www.indeed.com/company/CentraNic-Ltd/jobs/Group-Financial-Data-Analyst-59999e06fd4b9009?fccid=004345d9813bd437&vjs=3\n",
      "Name: Job Url, dtype: object\n",
      "13    http://www.indeed.com/company/CriterionCapital/jobs/Office-Administration-Assistant-64da8cde37d422d9?fccid=1931435125b82129&vjs=3\n",
      "Name: Job Url, dtype: object\n",
      "17    http://www.indeed.com/pagead/clk?mo=r&ad=-6NYlbfkN0BIQv-klv4x57wzcCCXZDuUs4ETBBTY7U4BZbqajjMT5rLx4iIBIgIDjvqIt6UO8LKeIOY33Wnt4_eGGFmqJeUFdqLBu7U5oyAp-J0dXDp4UiTLVL041HcriHxDT6myJ6B1t5jySkfSP0xrQ1MSGJug_oWZSIBng5uU3tgIaZmdrw1f0HFsYk5o_w5zejOWcDSmC6lgzvZJ6vOa82rSFId3FatHT_qfXMi-PufkEZX4WyY6n0oncWV21jlODJXWsKuoJYw7GGwET4yAfy66eZiJmeyDU1xf9Dt8-V27KKcbAybIWSHq7Mjgv8OjIYZvnDEPVvDV5XHAtg10Eimq-WRh4abc6WEORw6KeHRnDyo2JYUI_WLt98BE3GEtIU9J_2zOiS1fykc7VgdRV6Zb9Gbk5l3k44WDTbVg7sH7h6rRjCG67hJvDDgIMKNCQzMTdIY=&p=2&fvj=1&vjs=3\n",
      "Name: Job Url, dtype: object\n",
      "14    http://www.indeed.com/company/Agina-ltd/jobs/Office-Administrator-d3d925d98ebd3d3d?fccid=33d409a0d113e3d3&vjs=3\n",
      "Name: Job Url, dtype: object\n",
      "149    http://www.indeed.com/company/Builder-Depot/jobs/Packing-Dispatch-Warehouse-Assistant-4128a5380a31f2fe?fccid=9ee965538d152761&vjs=3\n",
      "Name: Job Url, dtype: object\n"
     ]
    }
   ],
   "source": [
    "## Printing some jobs that are fitting better to your CV\n",
    "pd.options.display.max_colwidth = 1000\n",
    "\n",
    "def get_title_from_url(index):\n",
    "    return final_data[final_data.index == index][\"Job Url\"]\n",
    "i=0\n",
    "for job in sorted_similar_jobs:\n",
    "    print(get_title_from_url(job[0]))\n",
    "    i=i+1\n",
    "    if i>5:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>similarity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>109</td>\n",
       "      <td>0.267647</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>13</td>\n",
       "      <td>0.241873</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>17</td>\n",
       "      <td>0.235511</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>14</td>\n",
       "      <td>0.228863</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>149</td>\n",
       "      <td>0.226240</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index  similarity\n",
       "0    109    0.267647\n",
       "1     13    0.241873\n",
       "2     17    0.235511\n",
       "3     14    0.228863\n",
       "4    149    0.226240"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Take only the links and send an email to the person that is looking for a position similar to their CV \n",
    "df = pd.DataFrame(sorted_similar_jobs[1:6], columns=[\"index\", \"similarity\"])\n",
    "df    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "http://www.indeed.com/company/CentraNic-Ltd/jobs/Group-Financial-Data-Analyst-59999e06fd4b9009?fccid=004345d9813bd437&vjs=3\n",
      "\n",
      "http://www.indeed.com/company/CriterionCapital/jobs/Office-Administration-Assistant-64da8cde37d422d9?fccid=1931435125b82129&vjs=3\n",
      "\n",
      "http://www.indeed.com/pagead/clk?mo=r&ad=-6NYlbfkN0BIQv-klv4x57wzcCCXZDuUs4ETBBTY7U4BZbqajjMT5rLx4iIBIgIDjvqIt6UO8LKeIOY33Wnt4_eGGFmqJeUFdqLBu7U5oyAp-J0dXDp4UiTLVL041HcriHxDT6myJ6B1t5jySkfSP0xrQ1MSGJug_oWZSIBng5uU3tgIaZmdrw1f0HFsYk5o_w5zejOWcDSmC6lgzvZJ6vOa82rSFId3FatHT_qfXMi-PufkEZX4WyY6n0oncWV21jlODJXWsKuoJYw7GGwET4yAfy66eZiJmeyDU1xf9Dt8-V27KKcbAybIWSHq7Mjgv8OjIYZvnDEPVvDV5XHAtg10Eimq-WRh4abc6WEORw6KeHRnDyo2JYUI_WLt98BE3GEtIU9J_2zOiS1fykc7VgdRV6Zb9Gbk5l3k44WDTbVg7sH7h6rRjCG67hJvDDgIMKNCQzMTdIY=&p=2&fvj=1&vjs=3\n",
      "\n",
      "http://www.indeed.com/company/Agina-ltd/jobs/Office-Administrator-d3d925d98ebd3d3d?fccid=33d409a0d113e3d3&vjs=3\n",
      "\n",
      "http://www.indeed.com/company/Builder-Depot/jobs/Packing-Dispatch-Warehouse-Assistant-4128a5380a31f2fe?fccid=9ee965538d152761&vjs=3\n"
     ]
    }
   ],
   "source": [
    "## Above is a dataframe with the job's index and the degree of job similarity based on the CV that I uploaded\n",
    "## I need the Links in a text shape in order to create the message, thus I found the links using the data frame indexes\n",
    "## and I saved them into a text file\n",
    "\n",
    "text = []\n",
    "for i in df[\"index\"]:\n",
    "    text.append(final_data[\"Job Url\"].iloc[i])\n",
    "    with open(\"message.txt\", 'w') as f:\n",
    "         f.write(\"\\n\\n\".join(map(str, text)))\n",
    "\n",
    "file = open('message.txt','r')\n",
    "\n",
    "#read the numbers on the file\n",
    "body = file.read()\n",
    "\n",
    "#Close the the numbers file\n",
    "file.close()\n",
    "\n",
    "#Print the Links, in other words the text that I will produce the messages\n",
    "print(body)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The final step is to send an email to the candidate using the smtplib module. I also attached an image at the bottom of the email."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "## First step, open my gmail account\n",
    "## Read a file with my personal info\n",
    "file = open(\"my_personal_file.txt\")\n",
    "lines = file.readlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully Sent email !!!\n",
      "Successfully Sent email !!!\n"
     ]
    }
   ],
   "source": [
    "import smtplib\n",
    "import imghdr\n",
    "from email.message import EmailMessage\n",
    "Sender_Email = \"nikoskalikis@gmail.com\"\n",
    "\n",
    "# You can send the emails with two methods, 1) By sending an email to every person in your list, \n",
    "## so everyone will be able to see the other person that you have in your list\n",
    "## OR 2) to every person separately which is the method that I used.\n",
    "\n",
    "Reciever_Email = [\"nikoskalikis@gmail.com\", \"despoina615@hotmail.com\"]\n",
    "Password = lines[1]\n",
    "for i in Reciever_Email:\n",
    "    try:\n",
    "        newMessage = EmailMessage()                         \n",
    "        newMessage['Subject'] = \"Check some new positions for you!!!\" \n",
    "        newMessage['From'] = Sender_Email                   \n",
    "        newMessage['To'] = i                   \n",
    "        newMessage.set_content(f\"Apply to the following positions\\n\\n \" + body) \n",
    "        with open('logo.png', 'rb') as f:\n",
    "            image_data = f.read()\n",
    "            image_type = imghdr.what(f.name)\n",
    "            image_name = f.name\n",
    "        newMessage.add_attachment(image_data, maintype='image', subtype=image_type, filename=image_name)\n",
    "        with smtplib.SMTP_SSL('smtp.gmail.com', 465) as smtp:\n",
    "\n",
    "            smtp.login(Sender_Email, Password)              \n",
    "            smtp.send_message(newMessage)\n",
    "            print(\"Successfully Sent email !!!\")\n",
    "    except Exception:\n",
    "           print(\"Error: unable to send email\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7 (tensorflow)",
   "language": "python",
   "name": "tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
